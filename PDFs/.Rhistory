install.packages("xlsx")
#Load Libraries
library(tidyverse)
library(pdftools)
library(xlsx)
install.packages("openxlsx")
library(openxlsx)
ConsolidatedComments <- function(x=importpath, y=exportpath){
file_names <- paste0(x,dir(x)) #creates a list of filenames with path for import
list_names <- dir(x) #creates a list of file names to identify imported files
my_list <- lapply(file_names, pdf_text)  #import files into a list
names(my_list) <- list_names #assign each list item its name from the imported document
my_list %>%
map_df(as_tibble, .id="Source_Document")->allSummaries #create a tibble from the list of lists
#cleaning data and separating into columns
allSummaries %>%
mutate(value=str_squish(value)) %>%
mutate(value= str_extract(value, "Page:(?s)(.*$)")) %>%
separate(value, into = c("Page", "value"), sep="\\s(?=[^,\\s]*Author:)", extra="merge" ) %>%
separate(value, into = c("Author", "value"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(value, into = c("Subject", "value"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(value, into = c("Date", "value"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(value=str_sub(value,4))->AS1
#identify the max number of individual comments in a combined text block for separating
n_vars <- AS1$value %>% str_count(pattern = "Author:") %>% max(na.rm = T) + 1
#separate a text block with multiple comments into individual comment rows
AS1 %>%
separate(value, into=c(head(LETTERS,n_vars)), sep="\\s(?=[^,\\s]*Author:)", extra="merge") %>%
pivot_longer(cols=c(head(LETTERS,n_vars)), names_to="Head", values_to= "Text" ) %>%
filter(!is.na(Text)) %>%
select(-Head)->AS2
#Subset into dataframes that had multiple comments that need cleaning and rows with single comments that are fine
needSeparate <-
AS2 %>%
filter(grepl("Author:",Text))
completed <-
AS2 %>%
filter(!grepl("Author:",Text))
#separate and clean subset that had multiple comments
needSeparate %>%
separate(Text, into = c("Author1", "Text"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(Text, into = c("Subject1", "Text"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(Text, into = c("Date1", "Text"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(Author=Author1,
Subject=Subject1,
Date=Date1) %>%
select(-Author1, -Subject1, -Date1)->separated
CompleteList <- bind_rows(completed, separated) #combine cleaned tables into one
#remove unnecessary header information from column contents
CompleteList %>%
mutate(Page= str_extract(Page,"Page:\\s"),
Author= str_remove(Author, "Author:\\s"),
Subject= str_remove(Subject,"Subject:\\s"),
Date= str_remove(Date, "Date:\\s"))->ListofComments
ListofComments$Page <- as.numeric(ListofComments$Page)#Change Page column from character to numeric
write_csv(ListofComments, y) #export a .csv file
}
ConsolidatedComments <- function(x=importpath, y=exportpath){
file_names <- paste0(x,dir(x)) #creates a list of filenames with path for import
list_names <- dir(x) #creates a list of file names to identify imported files
my_list <- lapply(file_names, pdf_text)  #import files into a list
names(my_list) <- list_names #assign each list item its name from the imported document
my_list %>%
map_df(as_tibble, .id="Source_Document")->allSummaries #create a tibble from the list of lists
#cleaning data and separating into columns
allSummaries %>%
mutate(value=str_squish(value)) %>%
mutate(value= str_extract(value, "Page:(?s)(.*$)")) %>%
separate(value, into = c("Page", "value"), sep="\\s(?=[^,\\s]*Author:)", extra="merge" ) %>%
separate(value, into = c("Author", "value"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(value, into = c("Subject", "value"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(value, into = c("Date", "value"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(value=str_sub(value,4))->AS1
#identify the max number of individual comments in a combined text block for separating
n_vars <- AS1$value %>% str_count(pattern = "Author:") %>% max(na.rm = T) + 1
#separate a text block with multiple comments into individual comment rows
AS1 %>%
separate(value, into=c(head(LETTERS,n_vars)), sep="\\s(?=[^,\\s]*Author:)", extra="merge") %>%
pivot_longer(cols=c(head(LETTERS,n_vars)), names_to="Head", values_to= "Text" ) %>%
filter(!is.na(Text)) %>%
select(-Head)->AS2
#Subset into dataframes that had multiple comments that need cleaning and rows with single comments that are fine
needSeparate <-
AS2 %>%
filter(grepl("Author:",Text))
completed <-
AS2 %>%
filter(!grepl("Author:",Text))
#separate and clean subset that had multiple comments
needSeparate %>%
separate(Text, into = c("Author1", "Text"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(Text, into = c("Subject1", "Text"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(Text, into = c("Date1", "Text"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(Author=Author1,
Subject=Subject1,
Date=Date1) %>%
select(-Author1, -Subject1, -Date1)->separated
CompleteList <- bind_rows(completed, separated) #combine cleaned tables into one
#remove unnecessary header information from column contents
CompleteList %>%
mutate(Page= str_extract(Page,"Page:\\s"),
Author= str_remove(Author, "Author:\\s"),
Subject= str_remove(Subject,"Subject:\\s"),
Date= str_remove(Date, "Date:\\s"))->ListofComments
ListofComments$Page <- as.numeric(ListofComments$Page)#Change Page column from character to numeric
write_xlsx(ListofComments, y) #export a .xlsx file
}
# Call Function
ConsolidatedComments(x = "C:/Users/liscal/Downloads/AcrobatSummaries/",
y= "C:/Users/liscal/Downloads/AcrobatSummaries/testfile.xlsx")
#Load Libraries
library(tidyverse)
library(pdftools)
library(openxlsx)
ConsolidatedComments <- function(x=importpath, y=exportpath){
file_names <- paste0(x,dir(x)) #creates a list of filenames with path for import
list_names <- dir(x) #creates a list of file names to identify imported files
my_list <- lapply(file_names, pdf_text)  #import files into a list
names(my_list) <- list_names #assign each list item its name from the imported document
my_list %>%
map_df(as_tibble, .id="Source_Document")->allSummaries #create a tibble from the list of lists
#cleaning data and separating into columns
allSummaries %>%
mutate(value=str_squish(value)) %>%
mutate(value= str_extract(value, "Page:(?s)(.*$)")) %>%
separate(value, into = c("Page", "value"), sep="\\s(?=[^,\\s]*Author:)", extra="merge" ) %>%
separate(value, into = c("Author", "value"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(value, into = c("Subject", "value"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(value, into = c("Date", "value"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(value=str_sub(value,4))->AS1
#identify the max number of individual comments in a combined text block for separating
n_vars <- AS1$value %>% str_count(pattern = "Author:") %>% max(na.rm = T) + 1
#separate a text block with multiple comments into individual comment rows
AS1 %>%
separate(value, into=c(head(LETTERS,n_vars)), sep="\\s(?=[^,\\s]*Author:)", extra="merge") %>%
pivot_longer(cols=c(head(LETTERS,n_vars)), names_to="Head", values_to= "Text" ) %>%
filter(!is.na(Text)) %>%
select(-Head)->AS2
#Subset into dataframes that had multiple comments that need cleaning and rows with single comments that are fine
needSeparate <-
AS2 %>%
filter(grepl("Author:",Text))
completed <-
AS2 %>%
filter(!grepl("Author:",Text))
#separate and clean subset that had multiple comments
needSeparate %>%
separate(Text, into = c("Author1", "Text"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(Text, into = c("Subject1", "Text"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(Text, into = c("Date1", "Text"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(Author=Author1,
Subject=Subject1,
Date=Date1) %>%
select(-Author1, -Subject1, -Date1)->separated
CompleteList <- bind_rows(completed, separated) #combine cleaned tables into one
#remove unnecessary header information from column contents
CompleteList %>%
mutate(Page= str_extract(Page,"Page:\\s"),
Author= str_remove(Author, "Author:\\s"),
Subject= str_remove(Subject,"Subject:\\s"),
Date= str_remove(Date, "Date:\\s"))->ListofComments
ListofComments$Page <- as.numeric(ListofComments$Page)#Change Page column from character to numeric
write_xlsx(ListofComments, y) #export a .xlsx file
}
# Call Function
ConsolidatedComments(x = "C:/Users/liscal/Downloads/AcrobatSummaries/",
y= "C:/Users/liscal/Downloads/AcrobatSummaries/testfile.xlsx")
ikea <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-11-03/ikea.csv')
movies <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-09/movies.csv')
ikea %>%
mutate(category = fct_collapse(category,
"Bedroom" = c("Beds", "Wardrobes","Chests of drawers & drawer units"),
"Children's room" = c("Children's furniture", "Nursery furniture")
))
ikea %>%
mutate(category = fct_collapse(category,
"Bedroom" = c("Beds", "Wardrobes","Chests of drawers & drawer units"),
"Children's room" = c("Children's furniture", "Nursery furniture")
)) ->check
View(check)
distinct(check$category)
unique(check$category)
ikea %>%
mutate(colors_online = if_else(sellable_online == TRUE & other_colors == "Yes", "available", "not available"),
colors_online = as_factor(colors_online)) %>%
select(sellable_online, other_colors, colors_online)
ikea %>%
mutate(biggest_dimension = case_when(
depth > height & depth > width ~ "depth",
height > depth & height > width ~ "height",
width > depth & width > height ~ "width",
TRUE ~ "unclear"
),
biggest_dimension = as_factor(biggest_dimension)) %>%
select(depth, height, width, biggest_dimension)
ikea %>%
group_by(category) %>%
count() %>%
ungroup()
ikea %>%
group_by(category) %>%
count()
ikea %>%
mutate(price_c = price_eur - mean(price_eur)) %>%
select(price_eur, price_c)
ikea %>%
mutate(price_c = price_eur - mean(price_eur)) %>%
select(price_eur, price_c)
diamonds <- diamonds
write.xlsx(diamonds, "diamonds.xlsx")
getwd()
# Call Function
ConsolidatedComments(x = "C:/Users/liscal/Downloads/AcrobatSummaries/",
y= "C:/Users/liscal/Downloads/AcrobatSummaries/testfile.xlsx")
ConsolidatedComments <- function(x=importpath, y=exportpath){
file_names <- paste0(x,dir(x)) #creates a list of filenames with path for import
list_names <- dir(x) #creates a list of file names to identify imported files
my_list <- lapply(file_names, pdf_text)  #import files into a list
names(my_list) <- list_names #assign each list item its name from the imported document
my_list %>%
map_df(as_tibble, .id="Source_Document")->allSummaries #create a tibble from the list of lists
#cleaning data and separating into columns
allSummaries %>%
mutate(value=str_squish(value)) %>%
mutate(value= str_extract(value, "Page:(?s)(.*$)")) %>%
separate(value, into = c("Page", "value"), sep="\\s(?=[^,\\s]*Author:)", extra="merge" ) %>%
separate(value, into = c("Author", "value"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(value, into = c("Subject", "value"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(value, into = c("Date", "value"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(value=str_sub(value,4))->AS1
#identify the max number of individual comments in a combined text block for separating
n_vars <- AS1$value %>% str_count(pattern = "Author:") %>% max(na.rm = T) + 1
#separate a text block with multiple comments into individual comment rows
AS1 %>%
separate(value, into=c(head(LETTERS,n_vars)), sep="\\s(?=[^,\\s]*Author:)", extra="merge") %>%
pivot_longer(cols=c(head(LETTERS,n_vars)), names_to="Head", values_to= "Text" ) %>%
filter(!is.na(Text)) %>%
select(-Head)->AS2
#Subset into dataframes that had multiple comments that need cleaning and rows with single comments that are fine
needSeparate <-
AS2 %>%
filter(grepl("Author:",Text))
completed <-
AS2 %>%
filter(!grepl("Author:",Text))
#separate and clean subset that had multiple comments
needSeparate %>%
separate(Text, into = c("Author1", "Text"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(Text, into = c("Subject1", "Text"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(Text, into = c("Date1", "Text"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(Author=Author1,
Subject=Subject1,
Date=Date1) %>%
select(-Author1, -Subject1, -Date1)->separated
CompleteList <- bind_rows(completed, separated) #combine cleaned tables into one
#remove unnecessary header information from column contents
CompleteList %>%
mutate(Page= str_extract(Page,"Page:\\s"),
Author= str_remove(Author, "Author:\\s"),
Subject= str_remove(Subject,"Subject:\\s"),
Date= str_remove(Date, "Date:\\s"))->ListofComments
ListofComments$Page <- as.numeric(ListofComments$Page)#Change Page column from character to numeric
write.xlsx(ListofComments, y) #export a .xlsx file
}
ConsolidatedComments <- function(x=importpath, y=exportpath){
file_names <- paste0(x,dir(x)) #creates a list of filenames with path for import
list_names <- dir(x) #creates a list of file names to identify imported files
my_list <- lapply(file_names, pdf_text)  #import files into a list
names(my_list) <- list_names #assign each list item its name from the imported document
my_list %>%
map_df(as_tibble, .id="Source_Document")->allSummaries #create a tibble from the list of lists
#cleaning data and separating into columns
allSummaries %>%
mutate(value=str_squish(value)) %>%
mutate(value= str_extract(value, "Page:(?s)(.*$)")) %>%
separate(value, into = c("Page", "value"), sep="\\s(?=[^,\\s]*Author:)", extra="merge" ) %>%
separate(value, into = c("Author", "value"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(value, into = c("Subject", "value"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(value, into = c("Date", "value"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(value=str_sub(value,4))->AS1
#identify the max number of individual comments in a combined text block for separating
n_vars <- AS1$value %>% str_count(pattern = "Author:") %>% max(na.rm = T) + 1
#separate a text block with multiple comments into individual comment rows
AS1 %>%
separate(value, into=c(head(LETTERS,n_vars)), sep="\\s(?=[^,\\s]*Author:)", extra="merge") %>%
pivot_longer(cols=c(head(LETTERS,n_vars)), names_to="Head", values_to= "Text" ) %>%
filter(!is.na(Text)) %>%
select(-Head)->AS2
#Subset into dataframes that had multiple comments that need cleaning and rows with single comments that are fine
needSeparate <-
AS2 %>%
filter(grepl("Author:",Text))
completed <-
AS2 %>%
filter(!grepl("Author:",Text))
#separate and clean subset that had multiple comments
needSeparate %>%
separate(Text, into = c("Author1", "Text"), sep="\\s(?=[^,\\s]*Subject:)", extra="merge" ) %>%
separate(Text, into = c("Subject1", "Text"), sep="\\s(?=[^,\\s]*Date:)", extra="merge" ) %>%
separate(Text, into = c("Date1", "Text"), sep="\\s(?=[^,\\s][[:alpha:]])", extra="merge" ) %>%
mutate(Author=Author1,
Subject=Subject1,
Date=Date1) %>%
select(-Author1, -Subject1, -Date1)->separated
CompleteList <- bind_rows(completed, separated) #combine cleaned tables into one
#remove unnecessary header information from column contents
CompleteList %>%
mutate(Page= str_extract(Page,"Page:\\s"),
Author= str_remove(Author, "Author:\\s"),
Subject= str_remove(Subject,"Subject:\\s"),
Date= str_remove(Date, "Date:\\s"))->ListofComments
ListofComments$Page <- as.numeric(ListofComments$Page)#Change Page column from character to numeric
write.xlsx(ListofComments, y) #export a .xlsx file
}
# Call Function
ConsolidatedComments(x = "C:/Users/liscal/Downloads/AcrobatSummaries/",
y= "C:/Users/liscal/Downloads/testfile.xlsx")
